AND Meta-Analysis[PT] "
out1 <- batch_pubmed_download(pubmed_query_string = ml_query, batch_size = 180,dest_dir=
"D:/Data_R_Meta")
read.csv("D:/Data_R_Meta/easyPubMed_data_01.csv")
ml_query <- "COVID 19[TIAB] AND 2020/01/01:2020/06/27[DP]
AND Meta-Analysis[PT] "
out1 <- batch_pubmed_download(pubmed_query_string = ml_query, batch_size = 180,dest_dir=
"D:/Data_R_Meta", format = "xml")
# Retrive number of guideline articles regarding COVID 19 from january to july 2020
try({
covid_querry_guide <- get_pubmed_ids("COVID 19[TIAB] AND 2020/01/01:2020/06/27[DP]
Guideline[PT]")
print(covid_querry_guide$Count)
}, silent = TRUE)
# Retrive number of meta_analysis articles regarding COVID 19 from january to july 2020
try({
covid_querry_meta <- get_pubmed_ids("COVID 19[TIAB] AND 2020/01/01:2020/06/27[DP]
Meta-Analysis[PT] ")
print(covid_querry_meta$Count)
}, silent = TRUE)
# Retrive article through author
try({
my_query <- "Bartosz Nowak[AU]"
my_query <- get_pubmed_ids(pubmed_query_string = my_query)
my_data <- fetch_pubmed_data(my_query, encoding = "ASCII")
listed_articles <- articles_to_list(my_data)
custom_grep(listed_articles[[2]], "ArticleTitle", "char")}, silent = TRUE)
# Load easyPubMed package
library(easyPubMed)
# Retrive article through author
try({
my_query <- "Bartosz Nowak[AU]"
my_query <- get_pubmed_ids(pubmed_query_string = my_query)
my_data <- fetch_pubmed_data(my_query, encoding = "ASCII")
listed_articles <- articles_to_list(my_data)
custom_grep(listed_articles[[2]], "ArticleTitle", "char")}, silent = TRUE)
# Retrive number of all publicatons regarding COVID 19 from january to july 2020
try({
covid_querry_all <- get_pubmed_ids("COVID 19[TIAB] AND 2020/01/01:2020/06/27[DP]")
print(covid_querry_all$Count)
}, silent = TRUE)
# Retrive number of review articles regarding COVID 19 from january to july 2020
try({
covid_querry_review <- get_pubmed_ids("COVID 19[TIAB] AND 2020/01/01:2020/06/27[DP]
Review[PT] ")
print(covid_querry_review$Count)
}, silent = TRUE)
# Retrive number of meta_analysis articles regarding COVID 19 from january to july 2020
try({
covid_querry_meta <- get_pubmed_ids("COVID 19[TIAB] AND 2020/01/01:2020/06/27[DP]
Meta-Analysis[PT] ")
print(covid_querry_meta$Count)
}, silent = TRUE)
install.packages("xml2")
library(xml2)
xml_structure(out1)
library()
ml_query <- "COVID 19[TIAB] AND 2020/01/01:2020/06/27[DP]
AND Meta-Analysis[PT] "
out1 <- batch_pubmed_download(pubmed_query_string = ml_query, batch_size = 180, format = "xml")
# Load easyPubMed package
library(easyPubMed)
ml_query <- "COVID 19[TIAB] AND 2020/01/01:2020/06/27[DP]
AND Meta-Analysis[PT] "
out1 <- batch_pubmed_download(pubmed_query_string = ml_query, batch_size = 180, format = "xml")
readLines(out1[1])[1:30]
out1
xml_structure(out1)
xml_structure("out1")
xml_structure(out1)
library(xml2)
xml_structure(out1)
xml_text(out1)
ml_query <- "COVID 19[TIAB] AND 2020/01/01:2020/06/27[DP]
AND Meta-Analysis[PT] "
out1 <- batch_pubmed_download(pubmed_query_string = ml_query, batch_size = 180, format = "xml")
as_list(out1)
as_list("out1")
as_list("out1")
xml_structure(out1)
http_type(out1)
install.packages("httr")
library(httr)
http_type(out1)
ml_query <- "COVID 19[TIAB] AND 2020/01/01:2020/06/27[DP]
AND Meta-Analysis[PT] "
out1 <- batch_pubmed_download(pubmed_query_string = ml_query, batch_size = 180,
dest_dir = NULL, format = "xml")
readLines(out1[1])[1:30]
out1
xml_structure(easyPubMed_data_01.txt)
xml_structure("easyPubMed_data_01.txt")
View(my_query)
dami_query <- "Damiano Fantini[AU] AND 2018[PDAT]"
outfile <- batch_pubmed_download(dami_query, dest_file_prefix = "easyPM_ex001_")
listed_articles <- articles_to_list(pubmed_data = outfile)
custom_grep(listed_articles[[2]], "ArticleTitle", "char")
listed_articles
xml_structure(listed_articles)
xml_structure("listed_articles")
listed_articles
dami_query <- "Damiano Fantini[AU] AND 2018[PDAT]"
outfile <- batch_pubmed_download(dami_query, dest_file_prefix = "easyPM_ex001_")
listed_articles <- articles_to_df(pubmed_data = outfile)
custom_grep(listed_articles[[2]], "ArticleTitle", "char")
listed_articles
unlist(listed_articles)
str(listed_articles)
data.frame(listed_articles)
str(listed_articles)
install.packages("xml")
install.packages("XML")
library(XML)
xmlData <- xmlToDataFrame(listed_articles)
xmlData <- xmlToDataFrame("listed_articles")
dami_query <- "Damiano Fantini[AU] AND 2018[PDAT]"
outfile <- batch_pubmed_download(dami_query, dest_file_prefix = "easyPM_ex001_")
listed_articles <- articles_to_df(pubmed_data = outfile)
dami_query <- "Damiano Fantini[AU] AND 2018[PDAT]"
outfile <- batch_pubmed_download(dami_query, dest_file_prefix = "easyPM_ex001_")
listed_articles <- articles_to_list(pubmed_data = outfile)
custom_grep(listed_articles[[2]], "ArticleTitle", "char")
listed_articles
xmlData <- xmlToDataFrame(listed_articles)
ml_query <- "COVID 19[TIAB] AND 2020/01/01:2020/06/27[DP]
AND Meta-Analysis[PT] "
out1 <- batch_pubmed_download(pubmed_query_string = ml_query, batch_size = 180,
dest_dir = NULL, format = "xml")
readLines(out1[1])[1:30]
out1
xmldata <- xmlToDataFrame("easyPubMed_data_01.txt")
xmldata
xmldata <- xmlParse("easyPubMed_data_01.txt")
a <- xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle/DateCompleted/Year"))
a
a <- setNames(xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle/DateCompleted/Year")), "Year")
xmldata <- xmlParse("easyPubMed_data_01.txt")
a <- setNames(xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle/DateCompleted/Year")), "Year")
a
xmldata
a <- setNames(xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle/DateCompleted/Year")), "Year")
a <- setNames(xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle/DateCompleted/Year")), 'Year')
a <- setNames(xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticleSet/PubmedArticle/DateCompleted/Year")), 'Year')
a <- xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticleSet/PubmedArticle/DateCompleted/Year"))
a
a <- xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle/MedlineCitation Status/DateCompleted/Year"))
a <- xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle"))
a
a <- xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle/AffiliationInfo/Affiliation"))
a
install.packages("remotes")
install.packages("remotes")
remotes::install_github("JulFriedrich/miRetrieve")
a <- xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle/AffiliationInfo"))
xmldata <- xmlParse("easyPubMed_data_01.txt")
xmldata
a <- xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle/AffiliationInfo"))
library(XML)
xmldata <- xmlParse("easyPubMed_data_01.txt")
xmldata
a <- xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle/AffiliationInfo"))
a
a <- xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle/"))
a <- xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle"))
a
a <- xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle/MedlineCitation Status= MEDLINE Owner=NLM"))
a
a <- xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle/MedlineCitation Status= MEDLINE Owner=NLM"))
a <- xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle/@MedlineCitation Status"))
a
a <- xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle/@MedlineCitation Status/@Author ValidYN"))
a
a <- xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle/@MedlineCitation Status/@Author ValidYN/AffiliationInfo"))
a
a <- xmlToDataFrame(node = getNodeSet(xmldata,"//PubmedArticle/@MedlineCitation Status/@Author ValidYN/AffiliationInfo/Affiliation"))
a
install.packages("RISmed")
library(RISmed)
?country
Country(xmldata)
articles_to_list(xmldata, encoding = "UTF8", simplify = TRUE)
a <- articles_to_list(xmldata, encoding = "UTF8", simplify = TRUE)
library(easyPubMed)
a <- articles_to_list(xmldata, encoding = "UTF8", simplify = TRUE)
a
a <- articles_to_list(xmldata, encoding = "UTF8", simplify = FALSE)
a
xmldata
pubmed_pl_data2018 <- readRDS("C:/Users/Bartek/Dropbox/R/Polish scientists performance PubMed/Old projekt - Mikołaj/PubMed/pubmed_pl_data2018.rds")
pubmed_pl_data2018
data("EPMsamples")
print(EPMsamples$NUBL_1618$qry_st)
data("PubMed_stopwords")
head(PubMed_stopwords)
table_articles_byAuth(xmldata,included_authors = "all",
max_chars = 500,autofill = TRUE,dest_file = NULL,getKeywords = TRUE,encoding = "UTF8")
table_articles_byAuth(out1,included_authors = "all",
max_chars = 500,autofill = TRUE,dest_file = NULL,getKeywords = TRUE,encoding = "UTF8")
table_articles_byAuth(out1,included_authors = "all",
max_chars = 500,autofill = TRUE,dest_file = NULL,getKeywords = FALSE,encoding = "UTF8")
custom_grep(out1, tag, format = "list")
custom_grep(out1, Affiliation , format = "list")
custom_grep(out1, "Affiliation" , format = "list")
a <-custom_grep(out1, "Affiliation" , format = "list")
a
list(a)
str(a)
table_articles_byAuth(out1,included_authors = "all",
max_chars = 500,autofill = TRUE,dest_file = "D:/Data_R_Meta",getKeywords = FALSE,encoding = "UTF8")
a <- table_articles_byAuth(out1,included_authors = "all",
max_chars = 500,autofill = TRUE,dest_file = "D:/Data_R_Meta/Dane_meta",getKeywords = FALSE,encoding = "UTF8")
a
str(a)
a <- table_articles_byAuth(out1,included_authors = "all",
max_chars = 500,autofill = TRUE,dest_file = "D:/Data_R_Meta/Dane_meta.rds",getKeywords = FALSE,encoding = "UTF8")
Dane_meta <- readRDS("D:/Data_R_Meta/Dane_meta.rds")
Dane_meta <- readRDS("D:/Data_R_Meta/Dane_meta.rds")
Dane_meta <- readRDS("D:/Data_R_Meta/Dane_meta.rds")
str(a)
library(tidyverse)
pubmed_pl_data2018 <- readRDS("C:/Users/Bartek/Dropbox/R/Polish scientists performance PubMed/Old projekt - Mikołaj/PubMed/pubmed_pl_data2018.rds")
pubmed_pl_data2018 <- readRDS("C:/Users/Bartek/Dropbox/R/Polish scientists performance PubMed/Old projekt - Mikołaj/PubMed/pubmed_pl_data2018.rds")
pubmed_pl_data2018
pubmed_pl_data2017 <- readRDS("C:/Users/Bartek/Dropbox/R/Polish scientists performance PubMed/Old projekt - Mikołaj/PubMed/pubmed_pl_data2017.rds")
pubmed_pl_data2017
dami_query <- "Damiano Fantini[AU] AND 2017[PDAT]"
dami_on_pubmed <- get_pubmed_ids(dami_query)
dami_abstracts_xml <- fetch_pubmed_data(dami_on_pubmed)
dami_abstracts_list <- articles_to_list(dami_abstracts_xml)
article_to_df(pubmedArticle = dami_abstracts_list[[1]], autofill = FALSE)
article_to_df(pubmedArticle = dami_abstracts_list[[2]], autofill = TRUE, max_chars = 300)[1:2,]
str(a)
pubmed_pl_data2017
b <- data.frame('pmid'= PMID(a))
b <- data.frame(pmid= PMID(a))
b <- data.frame("pmid"= PMID(a))
?data.frame
b <- data.frame(a)
b
str(a)
pubmed_pl_data2017
as.tibble(a)
as_tibble(a)
select(a,-abstract)
a
select(a,-abstract)
a
as_tibble(a)
as_tibble(a)
a
as_tibble(a)
a
b <- as_tibble(a)
b
c <- b %>%
select(-abstract)
c
c <- b %>%
select(-abstract, -keywords)
c
c <- b %>%
select(-abstract, -keywords,-email)
c
c
pubmed_pl_data2017
a
c
pubmed_pl_data2017
c
a
c
c
c
a
c
d <- distinct(c,address)
d
library(countrycode)
install.packages("countrycode")
library(countrycode)
city_country <- read.csv("https://raw.githubusercontent.com/girijesh18/dataset/master/City_and_province_list.csv")
city_country <- city_country[!duplicated(city_country$City), ]
d
df$country <- countrycode(df$d, "City", "Country",
custom_dict = city_country)
city_country
df$country <- countrycode($d, "City", "Country",
custom_dict = city_country)
df$country <- countrycode(d, "City", "Country",
custom_dict = city_country)
e <- as_data_frame(d)
e
e <- as_data_frame(d)
e
df$country <- countrycode(e, "City", "Country",
custom_dict = city_country)
?as_data_frame
e <- as.data.frame(d)
e
df$country <- countrycode(e, "City", "Country",
custom_dict = city_country)
df$country <- countrycode(df$e, "City", "Country",
custom_dict = city_country)
library(countrycode)
city_country <- read.csv("https://raw.githubusercontent.com/girijesh18/dataset/master/City_and_province_list.csv")
city_country <- city_country[!duplicated(city_country$City), ]
city_country
df$country <- countrycode(df$e, "City", "Country",
custom_dict = city_country)
e
org_loc <- c("Zug", "Zug  Canton of Zug", "Zimbabwe", "Zigong", "Zhuhai",
"Zaragoza", "York  United Kingdom", "Delhi",
"Yalleroi  Queensland", "Waterloo  Ontario", "Waterloo  ON",
"Washington  D.C.", "Washington D.C. Metro", "New York")
df <- data.frame(org_loc)
city_country <- read.csv("https://raw.githubusercontent.com/girijesh18/dataset/master/City_and_province_list.csv")
# custom_dict for countrycode cannot have duplicate origin codes
city_country <- city_country[!duplicated(city_country$City), ]
df$country <- countrycode(df$org_loc, "City", "Country",
custom_dict = city_country)
df$country
library(maps)
install.packages("maps")
install.packages("plyr")
library(maps)
library(plyr)
caa <- gsub(e, "[[:punct:]]", "")
e
library(world.cities)
data(world.cities)
aa <- c(
"Mechanical and Production Engineering Department, National University of Singapore.",
"Cancer Research Campaign Mammalian Cell DNA Repair Group, Department of Zoology, Cambridge, U.K.",
"Cancer Research Campaign Mammalian Cell DNA Repair Group, Department of Zoology, Cambridge, UK.",
"Lilly Research Laboratories, Eli Lilly and Company, Indianapolis, IN 46285."
)
# Remove punctuation from data
caa <- gsub(aa, "[[:punct:]]", "")    ### *Edit*
caa
# Split data at word boundaries
saa <- strsplit(caa, " ")
saa
# Match on cities in world.cities
# Assumes that if multiple matches, the last takes precedence, i.e. max()
llply(saa, function(x)x[max(which(x %in% world.cities$name))])
# Match on country in world.countries
llply(saa, function(x)x[which(x %in% world.cities$country.etc)])
data("world.cities")
e <- gsub("[[:punct:]\n]","",e)
raw2 <- strsplit(e, " ")
raw2
CountryList_raw <- (lapply(raw2, function(x)x[which(toupper(x) %in% toupper(world.cities$country.etc))]))
do.call(rbind, lapply(CountryList_raw, as.data.frame))
f <- do.call(rbind, lapply(CountryList_raw, as.data.frame))
f
f <- as_tibble(f)
f
as.character(f)
f
f
g <- f %>%
group_by(i)
str(f)
summarize(f)
f
summarize(f)
levels(f)
g <- f %>%
group_by(X[[i]])
f <- do.call(rbind, lapply(CountryList_raw, as.data.frame))
f
f <- as.character(f)
f
f
f
f <- do.call(rbind, lapply(CountryList_raw, as.data.frame))
f
summarise(f)
f
f <- as_tibble(f)
f
str(f)
install.packages("data.table")
library
library(data.table)
DT<-data.table(x=sample(1:10,1E7,TRUE))
# Count Frequency of each factor level
DT[,.N,by=x]
DT<-data.table(f)
# Count Frequency of each factor level
DT[,.N,by=x]
# Count Frequency of each factor level
DT[,.N,by=i]
# Count Frequency of each factor level
DT[,.N,by=[[i]]]
DT
# Count Frequency of each factor level
DT[,.N,by=X[[i]]]
levels(DT)
f <- as_tibble(f)
f
f <- do.call(rbind, lapply(CountryList_raw, as.data.frame))
f
str(f)
levels(f)
f <- factor(f,levels=TRUE)
str(f)
f
?factor
f <- as_tibble(f)
f
f <- do.call(rbind, lapply(CountryList_raw, as.data.frame))
f <- factor(f,levels=TRUE)
f
f <- do.call(rbind, lapply(CountryList_raw, as.data.frame))
f
str(f)
count(f)
# Retrive number of all publicatons regarding COVID 19 from january to july 2020
try({
covid_querry_all <- get_pubmed_ids("COVID 19[TIAB] OR novel coronavirus[TIAB] OR
coronavirus Wuhan[TIAB] OR SARS-CoV-2[TIAB] AND 2020/01/01:2020/06/27[DP]")
print(covid_querry_all$Count)
}, silent = TRUE)
# Retrive number of guideline articles regarding COVID 19 from january to july 2020
try({
covid_querry_guide <- get_pubmed_ids("COVID 19[TIAB] OR novel coronavirus[TIAB] OR
coronavirus Wuhan[TIAB] OR SARS-CoV-2[TIAB] AND 2020/01/01:2020/06/27[DP]")
print(covid_querry_guide$Count)
}, silent = TRUE)
# Retrieve number of all journal articles with abstract regarding COVID 19 from january to july 2020
try({
covid_querry_journal <- get_pubmed_ids("COVID 19[TIAB] OR novel coronavirus[TIAB] OR
coronavirus Wuhan[TIAB] OR SARS-CoV-2[TIAB] AND 2019/12/31:2020/06/30[DP]
Journal Article[PT] ")
print(covid_querry_journal$Count)
}, silent = TRUE)
# Retrieve number of all publications regarding COVID 19 from from 31th December to July 2020
try({
covid_querry_all <- get_pubmed_ids("COVID 19[TIAB] OR novel coronavirus[TIAB] OR
coronavirus Wuhan[TIAB] OR SARS-CoV-2[TIAB] AND 2019/12/31:2020/06/30[DP]")
print(covid_querry_all$Count)
}, silent = TRUE)
# Retrieve number of all publications regarding COVID 19 from from 31th December to July 2020
try({
covid_querry_all <- get_pubmed_ids("COVID 19[TIAB] OR novel coronavirus[TIAB] OR
coronavirus Wuhan[TIAB] OR SARS-CoV-2[TIAB] AND 2019/12/31:2020/06/30[DP]")
print(covid_querry_all$Count)
}, silent = TRUE)
# Retrieve number of review articles regarding COVID 19 from january to july 2020
try({
covid_querry_review <- get_pubmed_ids("COVID 19[TIAB] AND 2019/12/31:2020/06/30[DP]
Review[PT] ")
print(covid_querry_review$Count)
}, silent = TRUE)
# Retrieve number of all publications regarding COVID 19 from from 31th December to July 2020
try({
covid_querry_all <- get_pubmed_ids("COVID 19[TIAB] OR novel coronavirus[TIAB] OR
coronavirus Wuhan[TIAB] OR SARS-CoV-2[TIAB] AND 2019/12/31:2020/06/30[DP]")
print(covid_querry_all$Count)
}, silent = TRUE)
# Retrieve number of all publications regarding COVID 19 from from 31th December to July 2020
try({
covid_querry_all <- get_pubmed_ids("COVID 19[TIAB] AND novel coronavirus[TIAB] AND
coronavirus Wuhan[TIAB] AND SARS-CoV-2[TIAB] AND 2019/12/31:2020/06/30[DP]")
print(covid_querry_all$Count)
}, silent = TRUE)
# Retrieve number of all publications regarding COVID 19 from from 31th December to July 2020
try({
covid_querry_all <- get_pubmed_ids("COVID 19[TIAB] OR novel coronavirus[TIAB] OR
coronavirus Wuhan[TIAB] OR SARS-CoV-2[TIAB] AND 2019/12/31:2020/06/30[DP]")
print(covid_querry_all$Count)
}, silent = TRUE)
# Retrieve number of all publications regarding COVID 19 from from 31th December to July 2020
try({
covid_querry_all <- get_pubmed_ids("COVID 19[TIAB] OR novel coronavirus[TIAB] OR
coronavirus Wuhan[TIAB] OR SARS-CoV-2[TIAB] AND 2019/12/31:2020/06/30[DP]")
print(covid_querry_all$Count)
}, silent = TRUE)
# Retrieve number of review articles regarding COVID 19 from january to july 2020
try({
covid_querry_review <- get_pubmed_ids("COVID 19[TIAB] AND 2019/12/31:2020/06/30[DP]
Review[PT] ")
print(covid_querry_review$Count)
}, silent = TRUE)
# Retrieve number of meta_analysis articles regarding COVID 19 from january to july 2020
try({
covid_querry_meta <- get_pubmed_ids("COVID 19[TIAB] AND 2019/12/31:2020/06/30[DP]
Meta-Analysis[PT] ")
print(covid_querry_meta$Count)
}, silent = TRUE)
# Retrieve number of meta_analysis articles regarding COVID 19 from january to july 2020
try({
covid_querry_meta <- get_pubmed_ids("COVID 19[TIAB] AND 2019/12/31:2020/06/30[DP]
Meta-Analysis[PT] ")
print(covid_querry_meta$Count)
}, silent = TRUE)
# Retrieve number of guideline articles regarding COVID 19 from january to july 2020
try({
covid_querry_guide <- get_pubmed_ids("COVID 19[TIAB] AND 2019/12/31:2020/06/30[DP]
Guideline[PT]")
print(covid_querry_guide$Count)
}, silent = TRUE)
# Retrieve sets of articles regarding COVID 19 from 31th December to July 2020
ml_query <- "COVID 19[TIAB] OR novel coronavirus[TIAB] OR
coronavirus Wuhan[TIAB] OR SARS-CoV-2[TIAB] AND 2019/12/31:2020/06/30[DP]"
out1 <- batch_pubmed_download(pubmed_query_string = ml_query, batch_size = 180)
# Retrieve number of all publications regarding COVID 19 from from 31th December to July 2020
try({
covid_querry_all <- get_pubmed_ids("COVID 19[TIAB]  AND 2019/12/31:2020/06/30[DP]")
print(covid_querry_all$Count)
}, silent = TRUE)
